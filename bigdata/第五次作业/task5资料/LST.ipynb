{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import lstat\n",
    "import scipy\n",
    "from scipy import io\n",
    "import cv2 as cv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二、数据预处理，生成样本集\n",
    "2.1、定义函数 mat2csv 将.mat文件转为.csv格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat2csv(mat_pathname,data_features,csv_pathname):\n",
    "    df=scipy.io.loadmat(mat_pathname)\n",
    "    features=df[data_features]\n",
    "    dfdata=pd.DataFrame(data=features)\n",
    "    dfdata.to_csv(csv_pathname,index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1*、执行函数mat2csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2csv('lb2.mat','lb2','lb2_HEADER.csv')\n",
    "mat2csv('ah2.mat','ah2','ah2.csv')\n",
    "#mat2csv('X2.mat','X2','X2.csv')\n",
    "#mat2csv('Y2.mat','Y2','Y2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2、定义函数csv转list，将csv文件内容逐行读取到列表中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2list(mat_pathname):\n",
    "    with open(mat_pathname, 'r') as f:\n",
    "         reader = csv.reader(f)\n",
    "         list=[]\n",
    "         for row in reader:\n",
    "             list+=row\n",
    "    return list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2*、执行csv2list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb2=csv2list('lb2.csv')\n",
    "ah2=csv2list('ah2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159967 159967\n"
     ]
    }
   ],
   "source": [
    "print(len(lb2),len(ah2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3、定义函数get_density(),获取并处理图像信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_density(img_path_name):\n",
    "    #导入\n",
    "    print(img_path_name)\n",
    "    img = cv.imread(img_path_name,2)\n",
    "    img_width=len(img[0])\n",
    "    img_height=len(img)\n",
    "    print('原尺寸:',img_width,img_height)\n",
    "    #标准化尺寸\n",
    "    img_out=cv.resize(img,(461,347))\n",
    "    img_width_out=len(img_out[0])\n",
    "    img_height_out=len(img_out)\n",
    "    print('标准化尺寸：',img_width_out,img_height_out)\n",
    "    #扁平化输出\n",
    "    img_out=img_out.flatten()\n",
    "    print('扁平化数组长度：',len(img_out),'\\n')\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3*执行函数get_density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LST.tif\n",
      "原尺寸: 281 218\n",
      "标准化尺寸： 461 347\n",
      "扁平化数组长度： 159967 \n",
      "\n",
      "Forest_height_2019_SASIAutm49n.tif\n",
      "原尺寸: 280 217\n",
      "标准化尺寸： 461 347\n",
      "扁平化数组长度： 159967 \n",
      "\n",
      "terrain.tif\n",
      "原尺寸: 308 278\n",
      "标准化尺寸： 461 347\n",
      "扁平化数组长度： 159967 \n",
      "\n",
      "impervious_surface_percentage_geographic_1000mutm49.tif\n",
      "原尺寸: 396 361\n",
      "标准化尺寸： 461 347\n",
      "扁平化数组长度： 159967 \n",
      "\n",
      "population.tif\n",
      "原尺寸: 356 325\n",
      "标准化尺寸： 461 347\n",
      "扁平化数组长度： 159967 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "LST=get_density('LST.tif')\n",
    "forest_height=get_density('Forest_height_2019_SASIAutm49n.tif')\n",
    "terrain=get_density('terrain.tif')\n",
    "impervious_surface_percentage=get_density('impervious_surface_percentage_geographic_1000mutm49.tif')\n",
    "population=get_density('population.tif')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4、定义函数build_sample()，用来生成样本集，存入sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sample():\n",
    "    dict={'ah2':ah2,'lb2':lb2,'population':population,\\\n",
    "        'terrain':terrain,'forest_height':forest_height,\\\n",
    "        'impervious_surface_percentage':impervious_surface_percentage,\\\n",
    "        'LST':LST}\n",
    "        \n",
    "    df=pd.DataFrame(dict)\n",
    "    df.to_csv('sample.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4*、执行 build_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三、导入样本集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'sample.csv'\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ah2  lb2  population  terrain  forest_height  \\\n",
      "0  0.0  0.0   317.87192      658             17   \n",
      "1  0.0  0.0   317.87195      714             16   \n",
      "2  0.0  0.0   317.87195      717             16   \n",
      "3  0.0  0.0   317.87195      509             13   \n",
      "4  0.0  0.0   317.87192      361             11   \n",
      "\n",
      "   impervious_surface_percentage  LST  \n",
      "0                            255  0.0  \n",
      "1                            255  0.0  \n",
      "2                            255  0.0  \n",
      "3                            255  0.0  \n",
      "4                            255  0.0  \n",
      "                ah2           lb2    population        terrain  forest_height  \\\n",
      "count  1.599670e+05  1.599670e+05  1.599670e+05  159967.000000  159967.000000   \n",
      "mean   3.563926e+05  6.013415e+04 -8.635121e+37   13269.607357      26.146812   \n",
      "std    1.008648e+06  1.841795e+05  1.466689e+38   23219.858147      36.146018   \n",
      "min    0.000000e+00  0.000000e+00 -3.402823e+38       1.000000       0.000000   \n",
      "25%    0.000000e+00  0.000000e+00 -2.399272e+38      37.000000       3.000000   \n",
      "50%    0.000000e+00  0.000000e+00  1.678436e+02     159.000000      10.000000   \n",
      "75%    4.287490e+04  6.784440e+03  4.162219e+02    4348.500000      23.000000   \n",
      "max    3.087815e+07  8.457094e+06  1.921539e+05   55537.000000     102.000000   \n",
      "\n",
      "       impervious_surface_percentage            LST  \n",
      "count                  159967.000000  159967.000000  \n",
      "mean                       14.358043     229.523212  \n",
      "std                        48.444873     116.921087  \n",
      "min                         0.000000       0.000000  \n",
      "25%                         0.000000     289.064597  \n",
      "50%                         0.000000     290.693322  \n",
      "75%                         1.000000     291.971705  \n",
      "max                       255.000000     296.001664  \n"
     ]
    }
   ],
   "source": [
    "#观察样本状况\n",
    "print(data.head())\n",
    "print(data.describe())\n",
    "#data.plot(kind='scatter',x='ah2',y='LST',figsize=(12,8))\n",
    "#plt.show()\n",
    "#set X (training data) and y (target variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1从样本集中将标签lable划分出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data.shape[1]\n",
    "X = data.iloc[:,0:cols-1]\n",
    "y = data.iloc[:,cols-1:cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ah2  lb2  population  terrain  forest_height  impervious_surface_percentage\n",
      "0  0.0  0.0   317.87192      658             17                            255\n",
      "1  0.0  0.0   317.87195      714             16                            255\n",
      "2  0.0  0.0   317.87195      717             16                            255\n",
      "3  0.0  0.0   317.87195      509             13                            255\n",
      "4  0.0  0.0   317.87192      361             11                            255\n",
      "   LST\n",
      "0  0.0\n",
      "1  0.0\n",
      "2  0.0\n",
      "3  0.0\n",
      "4  0.0\n",
      "   ah2  lb2  population  impervious_surface_percentage\n",
      "0  0.0  0.0   317.87192                            255\n",
      "1  0.0  0.0   317.87195                            255\n",
      "2  0.0  0.0   317.87195                            255\n",
      "3  0.0  0.0   317.87195                            255\n"
     ]
    }
   ],
   "source": [
    "#查看划分状况\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "print(X.iloc[0:4, [0, 1, 2, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2随机划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X.values,y.values,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "四、线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept_: [277.13772686]\n",
      "coef_: \n",
      " [[ 2.17484956e-68  0.00000000e+00  5.51081229e-37 -7.32765971e-71\n",
      "  -8.32946657e-74  5.35865857e-74]]\n",
      "Mean squared error: 6875.154201142223\n",
      "Variance score： 0.4974860979426504\n",
      "score： 0.4974860979426504\n",
      "time usage: 0.019991159439086914 s\n"
     ]
    }
   ],
   "source": [
    "#linear regression\n",
    "from sklearn import linear_model\n",
    "start=time.time()\n",
    "\n",
    "#fit 回归模型\n",
    "model=linear_model.LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "print('intercept_:',model.intercept_)\n",
    "print('coef_:','\\n',model.coef_)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "print('Mean squared error:',mean_squared_error(y_test,model.predict(X_test)))\n",
    "print ('Variance score：',r2_score(y_test,model.predict(X_test)))\n",
    "print('score：',model.score(X_test,y_test))\n",
    "print('time usage:',time.time()-start,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "五、梯度提升拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### light GBM regression ##########\n",
      "Mean squared error； 1801.5805695714844\n",
      "Variance score： 0.8683894690773961\n",
      "score： 0.8683894690773961\n",
      "time usage: 0.31507134437561035 s\n"
     ]
    }
   ],
   "source": [
    "#light GBM regression\n",
    "import lightgbm as lgb\n",
    "print('################### light GBM regression ##########')\n",
    "start=time.time()\n",
    "# #######################################################################\n",
    "#fit 回归模型\n",
    "#model = lgb.LGBMRegressor(num_leaves=31,learning_rate=0.05,n_estimators=20)\n",
    "model = lgb.LGBMRegressor()\n",
    "model.fit (X_train,y_train.ravel())\n",
    "\n",
    "#look at the result\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "print('Mean squared error；',mean_squared_error(y_test,model.predict(X_test)))\n",
    "print ('Variance score：',r2_score(y_test,model.predict(X_test)))\n",
    "print('score：',model.score(X_test,y_test))\n",
    "print('time usage:',time.time()-start,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from d2l import torch as d2l\n",
    "import random\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = torch.tensor(X_train, dtype=d2l.float32)\n",
    "test_features = torch.tensor(X_test, dtype=d2l.float32)\n",
    "train_labels = torch.tensor(y_train, dtype=d2l.float32)\n",
    "test_labels = torch.tensor(y_test, dtype=d2l.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):  \n",
    "    \"\"\"构造一个PyTorch数据迭代器。\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 300\n",
    "train_iter = load_array((train_features, train_labels), batch_size)\n",
    "test_iter = load_array((test_features, test_labels), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0000e+00,  0.0000e+00, -2.6029e+38,  5.5537e+04,  1.0100e+02,\n",
       "           3.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00, -3.4028e+38,  5.5537e+04,  1.0100e+02,\n",
       "           2.2900e+02],\n",
       "         [ 0.0000e+00,  0.0000e+00, -3.1949e+38,  7.8160e+03,  8.0000e+00,\n",
       "           0.0000e+00],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  2.2915e+02,  6.8000e+02,  9.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.1412e+02,  3.9000e+01,  6.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.2638e+02,  1.2000e+01,  2.8000e+01,\n",
       "           0.0000e+00]]),\n",
       " tensor([[  0.0000],\n",
       "         [  0.0000],\n",
       "         [291.1706],\n",
       "         [ 14.4488],\n",
       "         [  0.0000],\n",
       "         [  0.0000],\n",
       "         [293.0214],\n",
       "         [290.4715],\n",
       "         [291.6615],\n",
       "         [293.6688],\n",
       "         [290.0199],\n",
       "         [289.9095],\n",
       "         [291.0002],\n",
       "         [290.8986],\n",
       "         [293.6282],\n",
       "         [  0.0000],\n",
       "         [  0.0000],\n",
       "         [289.8026],\n",
       "         [  0.0000],\n",
       "         [294.8291],\n",
       "         [  0.0000],\n",
       "         [293.0140],\n",
       "         [293.9714],\n",
       "         [290.9781],\n",
       "         [290.9932],\n",
       "         [293.7357],\n",
       "         [290.7460],\n",
       "         [292.2090],\n",
       "         [290.5663],\n",
       "         [291.6090],\n",
       "         [291.1573],\n",
       "         [  0.0000],\n",
       "         [292.2665],\n",
       "         [291.9277],\n",
       "         [  0.0000],\n",
       "         [289.6014],\n",
       "         [  0.0000],\n",
       "         [289.3930],\n",
       "         [289.0883],\n",
       "         [292.5698],\n",
       "         [290.6585],\n",
       "         [290.0089],\n",
       "         [290.7588],\n",
       "         [290.6043],\n",
       "         [289.5781],\n",
       "         [  0.0000],\n",
       "         [291.1194],\n",
       "         [292.5140],\n",
       "         [290.9178],\n",
       "         [292.1351],\n",
       "         [292.5243],\n",
       "         [292.9125],\n",
       "         [292.6220],\n",
       "         [291.2822],\n",
       "         [290.6782],\n",
       "         [289.5964],\n",
       "         [291.1980],\n",
       "         [290.7485],\n",
       "         [291.2304],\n",
       "         [  0.0000],\n",
       "         [291.1523],\n",
       "         [195.6366],\n",
       "         [291.9857],\n",
       "         [  0.0000],\n",
       "         [292.3461],\n",
       "         [290.6485],\n",
       "         [292.3194],\n",
       "         [288.2983],\n",
       "         [289.5825],\n",
       "         [292.8750],\n",
       "         [289.8780],\n",
       "         [291.8740],\n",
       "         [291.1171],\n",
       "         [290.1634],\n",
       "         [ 77.3560],\n",
       "         [290.8211],\n",
       "         [293.7455],\n",
       "         [289.6539],\n",
       "         [291.6052],\n",
       "         [289.6874],\n",
       "         [290.5042],\n",
       "         [293.7895],\n",
       "         [290.9432],\n",
       "         [290.1425],\n",
       "         [  0.0000],\n",
       "         [  0.0000],\n",
       "         [290.6390],\n",
       "         [  0.0000],\n",
       "         [  0.0000],\n",
       "         [289.8152],\n",
       "         [290.6266],\n",
       "         [  0.0000],\n",
       "         [290.0623],\n",
       "         [292.8222],\n",
       "         [  0.0000],\n",
       "         [293.4311],\n",
       "         [291.6191],\n",
       "         [289.3912],\n",
       "         [290.4068],\n",
       "         [  0.0000],\n",
       "         [  0.0000],\n",
       "         [292.0713],\n",
       "         [293.6927],\n",
       "         [  0.0000],\n",
       "         [293.9511],\n",
       "         [292.9031],\n",
       "         [291.0907],\n",
       "         [294.1687],\n",
       "         [293.8014],\n",
       "         [290.6648],\n",
       "         [293.2445],\n",
       "         [289.4768],\n",
       "         [293.6761],\n",
       "         [290.5762],\n",
       "         [292.0764],\n",
       "         [291.2396],\n",
       "         [290.5751],\n",
       "         [293.8533],\n",
       "         [293.5889],\n",
       "         [290.6299],\n",
       "         [  0.0000],\n",
       "         [290.1910],\n",
       "         [143.1959],\n",
       "         [293.0779],\n",
       "         [288.3228],\n",
       "         [290.6708],\n",
       "         [290.8050],\n",
       "         [292.8689],\n",
       "         [288.7327],\n",
       "         [292.0064],\n",
       "         [  0.0000],\n",
       "         [290.1828],\n",
       "         [294.6382],\n",
       "         [293.6100],\n",
       "         [289.8905],\n",
       "         [  0.0000],\n",
       "         [289.4365],\n",
       "         [291.5450],\n",
       "         [175.6286],\n",
       "         [289.4055],\n",
       "         [291.5954],\n",
       "         [292.3709],\n",
       "         [293.2010],\n",
       "         [292.6809],\n",
       "         [231.8168],\n",
       "         [291.6331],\n",
       "         [292.1234],\n",
       "         [291.1258],\n",
       "         [291.9869],\n",
       "         [290.3532],\n",
       "         [  0.0000],\n",
       "         [293.4188],\n",
       "         [291.2242],\n",
       "         [293.2436],\n",
       "         [  0.0000],\n",
       "         [292.0701],\n",
       "         [292.5688],\n",
       "         [292.1731],\n",
       "         [290.1794],\n",
       "         [290.8649],\n",
       "         [  0.0000],\n",
       "         [292.7581],\n",
       "         [  0.0000],\n",
       "         [291.1152],\n",
       "         [292.1849],\n",
       "         [292.8083],\n",
       "         [291.5947],\n",
       "         [292.0305],\n",
       "         [  0.0000],\n",
       "         [291.0630],\n",
       "         [289.8003],\n",
       "         [292.8927],\n",
       "         [  0.0000],\n",
       "         [290.8068],\n",
       "         [  0.0000],\n",
       "         [294.2632],\n",
       "         [289.4731],\n",
       "         [  0.0000],\n",
       "         [  0.0000],\n",
       "         [  0.0000],\n",
       "         [292.2180],\n",
       "         [291.4638],\n",
       "         [292.7392],\n",
       "         [292.2400],\n",
       "         [289.3875],\n",
       "         [  0.0000],\n",
       "         [291.1053],\n",
       "         [290.5910],\n",
       "         [289.7687],\n",
       "         [  0.0000],\n",
       "         [290.0233],\n",
       "         [289.2880],\n",
       "         [290.2318],\n",
       "         [290.0232],\n",
       "         [291.5884],\n",
       "         [  0.0000],\n",
       "         [290.7374],\n",
       "         [291.6658],\n",
       "         [292.1506],\n",
       "         [  0.0000],\n",
       "         [290.5984],\n",
       "         [292.2581],\n",
       "         [290.7409],\n",
       "         [292.5438],\n",
       "         [291.0238],\n",
       "         [290.4433],\n",
       "         [289.3967],\n",
       "         [289.5798],\n",
       "         [290.9427],\n",
       "         [290.8493],\n",
       "         [291.7884],\n",
       "         [290.2917],\n",
       "         [289.4099],\n",
       "         [  0.0000],\n",
       "         [294.4988],\n",
       "         [  0.0000],\n",
       "         [292.4357],\n",
       "         [293.0747],\n",
       "         [288.9553],\n",
       "         [289.9107],\n",
       "         [  0.0000],\n",
       "         [290.3871],\n",
       "         [291.4607],\n",
       "         [288.9546],\n",
       "         [289.2861],\n",
       "         [  0.0000],\n",
       "         [291.4153],\n",
       "         [291.7318],\n",
       "         [292.4177],\n",
       "         [292.0750],\n",
       "         [291.7188],\n",
       "         [293.5990],\n",
       "         [100.3082],\n",
       "         [293.0413],\n",
       "         [291.6960],\n",
       "         [290.6853],\n",
       "         [290.9920],\n",
       "         [290.9500],\n",
       "         [291.9207],\n",
       "         [291.0990],\n",
       "         [  0.0000],\n",
       "         [  0.0000],\n",
       "         [292.5648],\n",
       "         [290.6179],\n",
       "         [  0.0000],\n",
       "         [291.0496],\n",
       "         [  0.0000],\n",
       "         [291.5151],\n",
       "         [289.9368],\n",
       "         [294.1638],\n",
       "         [293.1103],\n",
       "         [290.5708],\n",
       "         [293.5530],\n",
       "         [289.9135],\n",
       "         [291.5762],\n",
       "         [291.3970],\n",
       "         [  0.0000],\n",
       "         [293.2380],\n",
       "         [291.4306],\n",
       "         [291.5403],\n",
       "         [290.9291],\n",
       "         [  0.0000],\n",
       "         [289.6783],\n",
       "         [290.8401],\n",
       "         [  0.0000],\n",
       "         [293.1997],\n",
       "         [289.7768],\n",
       "         [290.9070],\n",
       "         [290.6876],\n",
       "         [290.9808],\n",
       "         [292.2574],\n",
       "         [291.0847],\n",
       "         [293.0371],\n",
       "         [290.2927],\n",
       "         [291.3492],\n",
       "         [290.4661],\n",
       "         [293.8946],\n",
       "         [293.9006],\n",
       "         [  0.0000],\n",
       "         [289.8602],\n",
       "         [  0.0000],\n",
       "         [290.5023],\n",
       "         [289.1784],\n",
       "         [267.3639],\n",
       "         [290.7267],\n",
       "         [291.2559],\n",
       "         [290.6920],\n",
       "         [  0.0000],\n",
       "         [284.5232],\n",
       "         [292.8867],\n",
       "         [  0.0000],\n",
       "         [293.9517],\n",
       "         [291.6271],\n",
       "         [293.1621],\n",
       "         [289.8114],\n",
       "         [289.9099],\n",
       "         [293.0192],\n",
       "         [288.6849],\n",
       "         [292.7654],\n",
       "         [ 38.7168]])]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Flatten(),nn.Linear(6, 3), nn.ReLU(),\n",
    "                    nn.Linear(3, 1) )\n",
    "net[1].weight.data.normal_(0, 0.01)\n",
    "net[1].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义损失和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, lr, num_epochs = 159968, 0.01, 10\n",
    "loss = nn.MSELoss()\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss nan\n",
      "epoch 2, loss nan\n",
      "epoch 3, loss nan\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in train_iter:\n",
    "        l = loss(net(X) ,y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(net(train_features), train_labels)\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-09022ea97e65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_ch3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\lib\\d2l\\torch.py\u001b[0m in \u001b[0;36mtrain_ch3\u001b[1;34m(net, train_iter, test_iter, loss, num_epochs, updater)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0manimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_metrics\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: nan"
     ]
    }
   ],
   "source": [
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-e0ddf0be00b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'epoch {epoch + 1}, loss {l:f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in train_iter:\n",
    "        l = loss(net(X) ,y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(net(features), labels)\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc5f70855ac006f3de45a3cc3b9e7d8d53845e50458809cb162b0174266dec97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
